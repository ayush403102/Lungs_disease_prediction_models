{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from google.colab import auth\n",
        "from google.colab import output\n",
        "import time\n",
        "\n",
        "# Authenticate user credentials\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set a timer for 6 hours\n",
        "timer = 6 * 60 * 60  # in seconds\n",
        "\n",
        "# Start time\n",
        "start = time.time()\n",
        "\n",
        "# Loop until the timer is up\n",
        "while time.time() - start < timer:\n",
        "  # Check if the runtime is still connected\n",
        "  if not output.is_streaming():\n",
        "    # If not, reconnect to the runtime\n",
        "    print(\"Reconnecting to runtime...\")\n",
        "    output.serve_kernel_port_as_iframe()\n",
        "  # Wait for 10 minutes before checking the connection status again\n",
        "  time.sleep(600)\n",
        "  \n",
        "# When the timer is up, print a message and disconnect the runtime\n",
        "print(\"Code execution completed. Disconnecting from runtime...\")\n",
        "output.eval_js('document.querySelector(\"#connect-button\").click()')\n"
      ],
      "metadata": {
        "id": "pDVtDYffUD-I"
      },
      "id": "pDVtDYffUD-I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amFIRnMXZ46W",
        "outputId": "b79b3098-194d-4c69-a7cb-1705e12e879b"
      },
      "id": "amFIRnMXZ46W",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Yes No/yes-no.zip\", 'r')\n",
        "# zip_ref.extractall(r\"/content/Yes No\")\n",
        "# zip_ref.close()\n"
      ],
      "metadata": {
        "id": "xfxIzKRncyPy"
      },
      "id": "xfxIzKRncyPy",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b9e4505b",
      "metadata": {
        "id": "b9e4505b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "DIRECTORY = r'/content/drive/MyDrive/rsna-pneumonia-detection-challenge/stage_2_train_png_images'\n",
        "CATEGORIES = ['Aug_Pneumonia', 'Aug_Normal']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# define the path to the input and output directories\n",
        "input_path = \"/content/drive/MyDrive/rsna-pneumonia-detection-challenge/stage_2_train_png_images/non-pneumonia\"\n",
        "output_path = \"/content/drive/MyDrive/rsna-pneumonia-detection-challenge/stage_2_train_png_images/Aug_Normal\"\n",
        "\n",
        "# create the output directory if it does not exist\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "# define the augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=(30), \n",
        "    width_shift_range=0.1, \n",
        "    height_shift_range=0.1, \n",
        "    shear_range=0.2, \n",
        "    zoom_range=0.2, \n",
        "    horizontal_flip=True, \n",
        "    fill_mode='nearest')\n",
        "kj = 0\n",
        "# loop over the images in the input directory\n",
        "for filename in os.listdir(input_path):\n",
        "    # load the image from disk\n",
        "    image = cv2.imread(os.path.join(input_path, filename))\n",
        "    # apply the augmentation and save the image to disk\n",
        "    for idx, batch in enumerate(datagen.flow(image.reshape(1, *image.shape), batch_size=1)):\n",
        "        # get the augmented image\n",
        "        augmented_image = batch[0].astype(\"uint8\")\n",
        "        # save the image to disk\n",
        "        cv2.imwrite(os.path.join(output_path, f\"{filename[:-4]}_{idx}.png\"), augmented_image)\n",
        "        # break out of the loop if we have generated the desired number of images\n",
        "        kj += 1\n",
        "        print(kj)\n",
        "        if idx == 1:\n",
        "            break\n"
      ],
      "metadata": {
        "id": "jEoWby5n9LrW"
      },
      "id": "jEoWby5n9LrW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dir_path = \"/content/drive/MyDrive/rsna-pneumonia-detection-challenge/stage_2_train_png_images/Aug_Normal\"\n",
        "\n",
        "num_images = len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])\n",
        "print(f\"Number of images in directory: {num_images}\")"
      ],
      "metadata": {
        "id": "EcWGmJ4eOaS9",
        "outputId": "a2d5835f-5aa0-4e56-d847-c8adf33baf91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EcWGmJ4eOaS9",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in directory: 12000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the image size, batch size, and number of classes\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# Define the data generator for training data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        DIRECTORY,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        classes=CATEGORIES,\n",
        "        subset='training')\n",
        "\n",
        "# Define the data generator for testing data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        DIRECTORY,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        classes=CATEGORIES,\n",
        "        subset='validation')\n"
      ],
      "metadata": {
        "id": "_QH2-y5RHsr_",
        "outputId": "df86fc13-485e-404c-b0ba-a1cf4fbab831",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_QH2-y5RHsr_",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18935 images belonging to 2 classes.\n",
            "Found 4733 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00faafa2",
      "metadata": {
        "id": "00faafa2"
      },
      "outputs": [],
      "source": [
        "# Works with dense net\n",
        "\n",
        "\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Flatten\n",
        "# from tensorflow.keras.applications.densenet import DenseNet121\n",
        "\n",
        "# # Load the DenseNet model\n",
        "# densenet = DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "# # Freeze the DenseNet layers\n",
        "# for layer in densenet.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # Create a Sequential model\n",
        "# model = Sequential()\n",
        "\n",
        "# # Add the DenseNet model to the Sequential model\n",
        "# model.add(densenet)\n",
        "\n",
        "# # Add a Flatten layer to the Sequential model\n",
        "# model.add(Flatten())\n",
        "\n",
        "# # Add a Dense layer to the Sequential model\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# # Add a Dense layer with softmax activation to the Sequential model\n",
        "# model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "df21d2fb",
      "metadata": {
        "id": "df21d2fb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "\n",
        "# Load the DenseNet model\n",
        "densenet = DenseNet201(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the first few layers of the DenseNet model\n",
        "for layer in densenet.layers[:100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the DenseNet model to the Sequential model\n",
        "model.add(densenet)\n",
        "\n",
        "# Add a Flatten layer to the Sequential model\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a Dense layer with 512 units and 'relu' activation\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Add a Dropout layer with a rate of 0.5\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# Add a Dense layer with 256 units and 'relu' activation\n",
        "model.add(Dense(256, activation='relu'))\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "# Add a Dropout layer with a rate of 0.5\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# Add a Dense layer with softmax activation\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model with a smaller learning rate and L2 regularization\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "f8aef8a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8aef8a5",
        "outputId": "6da30ea9-ac49-4acd-dfe5-ef3c33cbb17b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet201 (Functional)    (None, 7, 7, 1920)        18321984  \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 94080)             0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 64)                6021184   \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 256)               16640     \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,360,322\n",
            "Trainable params: 23,326,594\n",
            "Non-trainable params: 1,033,728\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=100,\n",
        "        validation_data=test_generator)"
      ],
      "metadata": {
        "id": "ZubVanM5I5Xv",
        "outputId": "9ba3cf4c-f369-4d1c-9659-2bfc9e8c96e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZubVanM5I5Xv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "592/592 [==============================] - 375s 464ms/step - loss: 0.6365 - accuracy: 0.7171 - val_loss: 0.5387 - val_accuracy: 0.7520\n",
            "Epoch 2/100\n",
            "592/592 [==============================] - 271s 458ms/step - loss: 0.5027 - accuracy: 0.7572 - val_loss: 0.7138 - val_accuracy: 0.6201\n",
            "Epoch 3/100\n",
            "592/592 [==============================] - 285s 481ms/step - loss: 0.4876 - accuracy: 0.7740 - val_loss: 0.5146 - val_accuracy: 0.7758\n",
            "Epoch 4/100\n",
            "592/592 [==============================] - 274s 462ms/step - loss: 0.4888 - accuracy: 0.7717 - val_loss: 0.6390 - val_accuracy: 0.6955\n",
            "Epoch 5/100\n",
            "592/592 [==============================] - 274s 463ms/step - loss: 0.4810 - accuracy: 0.7767 - val_loss: 0.4853 - val_accuracy: 0.7566\n",
            "Epoch 6/100\n",
            "592/592 [==============================] - 272s 459ms/step - loss: 0.4769 - accuracy: 0.7810 - val_loss: 0.4590 - val_accuracy: 0.7925\n",
            "Epoch 7/100\n",
            "592/592 [==============================] - 272s 459ms/step - loss: 0.4686 - accuracy: 0.7801 - val_loss: 0.4581 - val_accuracy: 0.7889\n",
            "Epoch 8/100\n",
            "592/592 [==============================] - 270s 456ms/step - loss: 0.4585 - accuracy: 0.7856 - val_loss: 0.5023 - val_accuracy: 0.7372\n",
            "Epoch 9/100\n",
            "592/592 [==============================] - 283s 478ms/step - loss: 0.4558 - accuracy: 0.7910 - val_loss: 0.4753 - val_accuracy: 0.7942\n",
            "Epoch 10/100\n",
            "592/592 [==============================] - 284s 479ms/step - loss: 0.4466 - accuracy: 0.7993 - val_loss: 0.4400 - val_accuracy: 0.8069\n",
            "Epoch 11/100\n",
            "592/592 [==============================] - 271s 458ms/step - loss: 0.4359 - accuracy: 0.8014 - val_loss: 0.4691 - val_accuracy: 0.7986\n",
            "Epoch 12/100\n",
            "203/592 [=========>....................] - ETA: 2:38 - loss: 0.4155 - accuracy: 0.8144"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "with open('history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "# Save the model\n",
        "model.save('my_model.h5')\n",
        "\n",
        "\n",
        "# Load the saved model from disk\n",
        "loaded_model = load_model('my_model.h5')\n"
      ],
      "metadata": {
        "id": "6fG_pWCHobFQ"
      },
      "id": "6fG_pWCHobFQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-DRotGIMi76r"
      },
      "id": "-DRotGIMi76r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot training & validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PhsjkufKjhwu"
      },
      "id": "PhsjkufKjhwu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46d8e517",
      "metadata": {
        "id": "46d8e517"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5d5bfae0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d5bfae0",
        "outputId": "0e8ea371-2e52-46ea-e866-ce89f0d52f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 98ms/step - loss: 2.7649 - accuracy: 0.6674\n",
            "Test accuracy: 66.73684120178223 %\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc* 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbdccb1d",
      "metadata": {
        "id": "dbdccb1d"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f47937dd",
      "metadata": {
        "id": "f47937dd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}